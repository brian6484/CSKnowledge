{
  "type": "excalidraw",
  "version": 2,
  "source": "https://excalidraw.com",
  "elements": [
    {
      "id": "_uk-7KDDBFQU5mXM5QA2n",
      "type": "rectangle",
      "x": 373.779262689799,
      "y": 794.4625705591252,
      "width": 985.4285103934153,
      "height": 592.5715718950546,
      "angle": 0,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "groupIds": [],
      "frameId": null,
      "index": "aU",
      "roundness": {
        "type": 3
      },
      "seed": 1832363592,
      "version": 186,
      "versionNonce": 148885304,
      "isDeleted": false,
      "boundElements": null,
      "updated": 1760577666650,
      "link": null,
      "locked": false
    },
    {
      "id": "AEwDiJz33uvCcZ_KMatzM",
      "type": "text",
      "x": 410.7792321722209,
      "y": 843.4625285974553,
      "width": 924.8593139648438,
      "height": 450,
      "angle": 0,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "groupIds": [],
      "frameId": null,
      "index": "aV",
      "roundness": null,
      "seed": 760041032,
      "version": 848,
      "versionNonce": 805846072,
      "isDeleted": false,
      "boundElements": null,
      "updated": 1760577866200,
      "link": null,
      "locked": false,
      "text": "situation: Online Chess Game with Leaderboard\n\nclairfying questions:\nis it strictly 1v1 with no observers allowed? observers allowed for future enhancement\nis there regional and global rank in leaderboard? yes and also time-based like daily, weekly,\ndo we have to detect the possible areas that this chess piece can move to? yes, server must\nvalidate all moves and all validation done on server side\ndo we keep game replays? yes store ranked games permanantely but delete casual games after \n30 days\nwats average gameplay data size?\n\nfunctional requirements:\n- global, regional and time-based leaderboard\n- 1v1 game play with casual and ranked modes\n- detect areas that this chess piece can move to \n- store ranked games permanently while deleting casual games after 30 days\n- replay gameplay\n",
      "fontSize": 20,
      "fontFamily": 5,
      "textAlign": "left",
      "verticalAlign": "top",
      "containerId": null,
      "originalText": "situation: Online Chess Game with Leaderboard\n\nclairfying questions:\nis it strictly 1v1 with no observers allowed? observers allowed for future enhancement\nis there regional and global rank in leaderboard? yes and also time-based like daily, weekly,\ndo we have to detect the possible areas that this chess piece can move to? yes, server must\nvalidate all moves and all validation done on server side\ndo we keep game replays? yes store ranked games permanantely but delete casual games after \n30 days\nwats average gameplay data size?\n\nfunctional requirements:\n- global, regional and time-based leaderboard\n- 1v1 game play with casual and ranked modes\n- detect areas that this chess piece can move to \n- store ranked games permanently while deleting casual games after 30 days\n- replay gameplay\n",
      "autoResize": true,
      "lineHeight": 1.25
    },
    {
      "id": "DYb9ZxjTeK1R855-Gw6ij",
      "type": "rectangle",
      "x": 1403.779248157619,
      "y": 802.4625474892894,
      "width": 1064.7618466331835,
      "height": 580.5714634486606,
      "angle": 0,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "groupIds": [],
      "frameId": null,
      "index": "aW",
      "roundness": {
        "type": 3
      },
      "seed": 530487112,
      "version": 170,
      "versionNonce": 2008439624,
      "isDeleted": false,
      "boundElements": null,
      "updated": 1760578888119,
      "link": null,
      "locked": false
    },
    {
      "id": "iM_xk9NkhJYlOmSWyiD9E",
      "type": "text",
      "x": 1434.3507116062794,
      "y": 837.3196816271243,
      "width": 1013.6591796875,
      "height": 500,
      "angle": 0,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "groupIds": [],
      "frameId": null,
      "index": "aX",
      "roundness": null,
      "seed": 2140800328,
      "version": 1127,
      "versionNonce": 273914440,
      "isDeleted": false,
      "boundElements": null,
      "updated": 1760578877859,
      "link": null,
      "locked": false,
      "text": "non-functional req:\nCAP theorem: should be CP? cuz if u see stale data (old moves) and u made certain moves against\nthem and suddenly it becomes consistent and all the moves were made redundant and invalidated,\nit is worse than being unavailable\n\nwrong! Im confusing game state consistency with CAP. for game it needs strong consistency like\nI said about stale moves, which is correct. It is ACID transaction on single game server. \nBut for overall system, it should be AP cuz since no 2 games depend on each other, even if theres\npartition, servers should accept games to increase availability, rather than not accept games to\nincrease conistency for leaderboard\n\ncalc:\nin-memory data is 10Kb/game, gamereplay in PGN format is 3Kb/game, 50k concurrent games, \n1M games/day\n\nin-memory data usage: 10K *50k = 500 M = 0.5Gb at any given time, manageable by typical server's RAM\ngameplay data usage: 1M * 3K = 3Gb/day = 90Gb/month of storage, not bad \n\n\n",
      "fontSize": 20,
      "fontFamily": 5,
      "textAlign": "left",
      "verticalAlign": "top",
      "containerId": null,
      "originalText": "non-functional req:\nCAP theorem: should be CP? cuz if u see stale data (old moves) and u made certain moves against\nthem and suddenly it becomes consistent and all the moves were made redundant and invalidated,\nit is worse than being unavailable\n\nwrong! Im confusing game state consistency with CAP. for game it needs strong consistency like\nI said about stale moves, which is correct. It is ACID transaction on single game server. \nBut for overall system, it should be AP cuz since no 2 games depend on each other, even if theres\npartition, servers should accept games to increase availability, rather than not accept games to\nincrease conistency for leaderboard\n\ncalc:\nin-memory data is 10Kb/game, gamereplay in PGN format is 3Kb/game, 50k concurrent games, \n1M games/day\n\nin-memory data usage: 10K *50k = 500 M = 0.5Gb at any given time, manageable by typical server's RAM\ngameplay data usage: 1M * 3K = 3Gb/day = 90Gb/month of storage, not bad \n\n\n",
      "autoResize": true,
      "lineHeight": 1.25
    },
    {
      "id": "0yamClllSXkqIyDjwpk6U",
      "type": "rectangle",
      "x": 384.16964221705706,
      "y": 1439.865658356744,
      "width": 1006.9999858311246,
      "height": 1478.285702296666,
      "angle": 0,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "groupIds": [],
      "frameId": null,
      "index": "aY",
      "roundness": {
        "type": 3
      },
      "seed": 1711927096,
      "version": 339,
      "versionNonce": 34009416,
      "isDeleted": false,
      "boundElements": null,
      "updated": 1760589542068,
      "link": null,
      "locked": false
    },
    {
      "id": "f25wuXz3E6DGWmNSyIJWQ",
      "type": "text",
      "x": 410.88389632385105,
      "y": 1464.7227706963088,
      "width": 972.2993774414062,
      "height": 1275,
      "angle": 0,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "groupIds": [],
      "frameId": null,
      "index": "aZ",
      "roundness": null,
      "seed": 1596157496,
      "version": 2835,
      "versionNonce": 1451037496,
      "isDeleted": false,
      "boundElements": null,
      "updated": 1760589870403,
      "link": null,
      "locked": false,
      "text": "high-level design:\ngeneral flow:\nclient -> lb -> user service (authentication, user profile, etc) and game service(match players\nin 1v1 in ranked/casual modes) -> user db(not bottleneck here, can just use postgres) , \ngameplay db(not sure postgres can store PGN but its just 90Gb/month so i think postgres\nshould be fine), leaderboard(gonna be read-heavy and with AP system needed, maybe \nCassandra with Redis cache? Not sure of the logic of leaderboard tho\n\nmaybe parition key is user_id and cluster key is user's ELO? but need cross-replica query and\nfrequent updates which is ex. maybe can just use redis only cuz i think leaderboard data is\nsmall <- this is true. Even if we partition by elo range and cluster by key with Cassandra, there\nis still uneven distribution and hot partition and still need cross partition query for top 100 \nSo use redis (explained more)\n\ngpt:\nits better to be SOLID (S) and separate each service's responsibility. My original design originally\nhad game service handle both matchmaking queue and the actual game connection. But separate \nit out.\n\nmatchmaking \npair 2 players by elo rating with Redis sorted set (member=user_id, score = ELO)\nZADD matchmaking_queue 1850 user_123\nZADD matchmaking_queue 1900 user_456\nZRANGEBYSCORE machmaking_queue 1800(min) 1900(max)\nZREM matchmaking_queue user_123 user_456\n\nleaderboard:\nonce match is done, update the elo\nZADD board 2000 user_123\nZADD board 1800 user_456\nZREVRANGE board 0 9 \n\ngame service:\nwebsocket connection for real-time moves and validates moves server side\n\ngame service storage: (redis for in-memory active games & postgres for gameplay history db)\nparition by game_id so that reads and writes for games are evenly distributed across nodes\nits bad to partition by user_id cuz might have hot users and uneven distribution\n\ngameplay history db:\nindex = fast lookup data structure (like book's index)\nindex by (user_id + timestamp) cuz most common query is show my recent games and this composite\nindex covers this for fast game look ups\n\nuser rating db in user service:\nso we not only use cache for ELO but we need single cold path - source of truth like db so we\nuse postgresql db\n\nindex: (elo_rating DESC, user_id) for leaderboard query\nwhen game ends, game service updates this user rating db and also update redis sorted set (async\nworker or trigger can do this)",
      "fontSize": 20,
      "fontFamily": 5,
      "textAlign": "left",
      "verticalAlign": "top",
      "containerId": null,
      "originalText": "high-level design:\ngeneral flow:\nclient -> lb -> user service (authentication, user profile, etc) and game service(match players\nin 1v1 in ranked/casual modes) -> user db(not bottleneck here, can just use postgres) , \ngameplay db(not sure postgres can store PGN but its just 90Gb/month so i think postgres\nshould be fine), leaderboard(gonna be read-heavy and with AP system needed, maybe \nCassandra with Redis cache? Not sure of the logic of leaderboard tho\n\nmaybe parition key is user_id and cluster key is user's ELO? but need cross-replica query and\nfrequent updates which is ex. maybe can just use redis only cuz i think leaderboard data is\nsmall <- this is true. Even if we partition by elo range and cluster by key with Cassandra, there\nis still uneven distribution and hot partition and still need cross partition query for top 100 \nSo use redis (explained more)\n\ngpt:\nits better to be SOLID (S) and separate each service's responsibility. My original design originally\nhad game service handle both matchmaking queue and the actual game connection. But separate \nit out.\n\nmatchmaking \npair 2 players by elo rating with Redis sorted set (member=user_id, score = ELO)\nZADD matchmaking_queue 1850 user_123\nZADD matchmaking_queue 1900 user_456\nZRANGEBYSCORE machmaking_queue 1800(min) 1900(max)\nZREM matchmaking_queue user_123 user_456\n\nleaderboard:\nonce match is done, update the elo\nZADD board 2000 user_123\nZADD board 1800 user_456\nZREVRANGE board 0 9 \n\ngame service:\nwebsocket connection for real-time moves and validates moves server side\n\ngame service storage: (redis for in-memory active games & postgres for gameplay history db)\nparition by game_id so that reads and writes for games are evenly distributed across nodes\nits bad to partition by user_id cuz might have hot users and uneven distribution\n\ngameplay history db:\nindex = fast lookup data structure (like book's index)\nindex by (user_id + timestamp) cuz most common query is show my recent games and this composite\nindex covers this for fast game look ups\n\nuser rating db in user service:\nso we not only use cache for ELO but we need single cold path - source of truth like db so we\nuse postgresql db\n\nindex: (elo_rating DESC, user_id) for leaderboard query\nwhen game ends, game service updates this user rating db and also update redis sorted set (async\nworker or trigger can do this)",
      "autoResize": true,
      "lineHeight": 1.25
    },
    {
      "id": "xtmiem43LZV8SVL_uUxY3",
      "type": "rectangle",
      "x": 1439.4556137223585,
      "y": 1452.8656452777814,
      "width": 1034.0000534057617,
      "height": 744.0000152587891,
      "angle": 0,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "groupIds": [],
      "frameId": null,
      "index": "ab",
      "roundness": {
        "type": 3
      },
      "seed": 1389077816,
      "version": 103,
      "versionNonce": 1188921160,
      "isDeleted": false,
      "boundElements": null,
      "updated": 1760589928405,
      "link": null,
      "locked": false
    },
    {
      "id": "Iy9PaXgsCbrTP6gDRc76V",
      "type": "text",
      "x": 1479.2056366105421,
      "y": 1476.6156452777814,
      "width": 978.6792602539062,
      "height": 400,
      "angle": 0,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "groupIds": [],
      "frameId": null,
      "index": "ac",
      "roundness": null,
      "seed": 1203768120,
      "version": 787,
      "versionNonce": 1309862456,
      "isDeleted": false,
      "boundElements": null,
      "updated": 1760590313145,
      "link": null,
      "locked": false,
      "text": "IMPT! for scaling and bottle neck:\n1) game service (websocket connection) \n- horizontal scaling with LB(sticky session by game_id cuz both players in same game need to \nconnect to same server)\n2) db writes\nwe need to insert 1 record to game history table, update 2 records in user rating \nthis can be decoupled as it is async operation\n\ngame ends -> kafka queue -> async workers(batch writes to postgres and update redis leaderboard)\n\nso db doesnt have to wait for db and it decouples **WRITE SPIKES**\n\n3)leaderboard redis\nthere can be too much reads so we use Redis + CDN!\n\nclient -> CDN (with short ttl like 10s) -> Redis -> postgres (rebuild redis on restart only) ",
      "fontSize": 20,
      "fontFamily": 5,
      "textAlign": "left",
      "verticalAlign": "top",
      "containerId": null,
      "originalText": "IMPT! for scaling and bottle neck:\n1) game service (websocket connection) \n- horizontal scaling with LB(sticky session by game_id cuz both players in same game need to \nconnect to same server)\n2) db writes\nwe need to insert 1 record to game history table, update 2 records in user rating \nthis can be decoupled as it is async operation\n\ngame ends -> kafka queue -> async workers(batch writes to postgres and update redis leaderboard)\n\nso db doesnt have to wait for db and it decouples **WRITE SPIKES**\n\n3)leaderboard redis\nthere can be too much reads so we use Redis + CDN!\n\nclient -> CDN (with short ttl like 10s) -> Redis -> postgres (rebuild redis on restart only) ",
      "autoResize": true,
      "lineHeight": 1.25
    },
    {
      "id": "6eB0hnrLUZPYvs7MftnCh",
      "type": "rectangle",
      "x": 2539.4556137223585,
      "y": 1460.8656853321027,
      "width": 917.0000457763672,
      "height": 744.0000247955322,
      "angle": 0,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "groupIds": [],
      "frameId": null,
      "index": "ad",
      "roundness": {
        "type": 3
      },
      "seed": 571980856,
      "version": 90,
      "versionNonce": 1549893944,
      "isDeleted": false,
      "boundElements": null,
      "updated": 1760590333948,
      "link": null,
      "locked": false
    },
    {
      "id": "b3_5VlaNMBKPIIp4SU7h2",
      "type": "text",
      "x": 2582.2056289811476,
      "y": 1487.8656643512677,
      "width": 974.5802001953125,
      "height": 6325,
      "angle": 0,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "groupIds": [],
      "frameId": null,
      "index": "ae",
      "roundness": null,
      "seed": 4414536,
      "version": 3,
      "versionNonce": 188672584,
      "isDeleted": false,
      "boundElements": null,
      "updated": 1760590335786,
      "link": null,
      "locked": false,
      "text": "## 1. Index Explanation: (elo_rating DESC, user_id)\n\n### How This Index Works:\n\n```sql\nCREATE INDEX idx_leaderboard ON user_ratings(elo_rating DESC, user_id);\n```\n\n**Index structure (simplified):**\n```\nELO (descending) | user_id     | → Row pointer\n-----------------|-------------|---------------\n2700             | user_789    | → Row in table\n2500             | user_123    | → Row in table\n2300             | user_456    | → Row in table\n2100             | user_999    | → Row in table\n...\n```\n\n### Why This Design?\n\n**Common query:**\n```sql\n-- Get top 100 players\nSELECT user_id, elo_rating, username \nFROM user_ratings \nORDER BY elo_rating DESC \nLIMIT 100;\n```\n\n**With this index:**\n1. Already sorted by ELO descending ✓\n2. Just read first 100 entries ✓\n3. No sorting needed ✓\n4. **O(100)** - constant time!\n\n**`user_id` as second column:**\n- Breaks ties (if two users have same ELO)\n- Makes index unique → better performance\n\n---\n\n## 2. Scaling & Bottlenecks\n\n### Current Load Recap:\n- 50K concurrent games\n- 3,300 moves/sec peak\n- 500K DAU\n- 1M games/day\n\n---\n\n### 🔴 Bottleneck #1: Game Service (WebSocket Connections)\n\n**Problem:**\n- Each game = 2 WebSocket connections\n- 50K games = **100K concurrent WebSocket connections**\n- Single server limit: ~10-20K connections\n\n**Solution: Horizontal Scaling**\n```\n                    ┌──────────────┐\nClient ────────────→│ Load Balancer│\n                    │ (sticky by   │\n                    │  game_id)    │\n                    └──────┬───────┘\n                           │\n        ┌──────────────────┼──────────────────┐\n        ▼                  ▼                  ▼\n   ┌─────────┐        ┌─────────┐       ┌─────────┐\n   │ Game    │        │ Game    │       │ Game    │\n   │ Server 1│        │ Server 2│       │ Server 3│\n   │ (20K    │        │ (20K    │       │ (20K    │\n   │  games) │        │  games) │       │  games) │\n   └─────────┘        └─────────┘       └─────────┘\n```\n\n**Key points:**\n- **Sticky sessions** - both players in same game connect to same server\n- 5-10 game servers for 50K concurrent games\n- Stateful servers (each holds active games in memory)\n\n---\n\n### 🔴 Bottleneck #2: Database Writes (Game Completion)\n\n**Problem:**\n- 24 games/sec completion = 24 writes/sec to Postgres\n- Each write updates:\n  - Game history table (insert)\n  - User ratings (2 updates per game)\n  - Stats tables (wins/losses)\n\n**Write amplification:** 24 games/sec × 4 DB operations = **~100 writes/sec**\n\n**Solution: Write-Behind Pattern**\n```\nGame ends ──→ Message Queue (Kafka/RabbitMQ)\n              │\n              ▼\n         ┌──────────────┐\n         │ Async Workers│ ──→ Batch writes to Postgres\n         │ (consumers)  │ ──→ Update Redis leaderboard\n         └──────────────┘\n```\n\n**Benefits:**\n- Game Service doesn't wait for DB\n- Batch multiple writes together\n- Retry on failure\n- Decouple write spikes\n\n---\n\n### 🔴 Bottleneck #3: Leaderboard Reads\n\n**Problem:**\n- Popular feature - users check rankings frequently\n- Potential: 500K DAU × 5 checks/day = **2.5M reads/day** = 30 reads/sec average\n\n**Solution: Redis + CDN**\n```\nClient ──→ CDN (cache top 1000 for 10 sec)\n           │ Cache miss\n           ▼\n         Redis (global leaderboard)\n           │ Cache miss (rare)\n           ▼\n         Postgres (source of truth)\n```\n\n**Caching strategy:**\n- **CDN/Edge cache:** Top 1000 players, TTL 10 seconds\n- **Redis:** Full leaderboard (10M users), always fresh\n- **Postgres:** Rebuild Redis on restart only\n\n---\n\n### 🔴 Bottleneck #4: Matchmaking at Scale\n\n**Problem:**\n- Peak: 50K concurrent games means ~50K new matchmaking requests/hour\n- Redis sorted set handles this, but queue management tricky\n\n**Challenges:**\n- Players wait too long if no close ELO match\n- Need to widen search range over time\n- Handle abandoned searches (player closes app)\n\n**Solution: Tiered Matchmaking**\n```python\n# Pseudocode\ndef find_match(user_id, elo):\n    ranges = [\n        (elo-50, elo+50),    # Try ±50 first (wait 5 sec)\n        (elo-100, elo+100),  # Widen to ±100 (wait 10 sec)\n        (elo-200, elo+200),  # Widen to ±200 (wait 15 sec)\n    ]\n    \n    for min_elo, max_elo in ranges:\n        opponent = redis.ZRANGEBYSCORE(queue, min_elo, max_elo, limit=1)\n        if opponent:\n            return opponent\n        sleep(5)  # Wait before widening\n    \n    return None  # No match found\n```\n\n**Plus:**\n- Background cleanup job removes stale entries (users who disconnected)\n- Separate queues per time control (blitz, rapid, etc.)\n\n---\n\n### 🔴 Bottleneck #5: Hot User Problem\n\n**Problem:**\n- Streamers/popular players: 100+ games/day\n- Their game history queries slow down\n- Their profile page gets hammered\n\n**Solution: User-level Caching**\n```\nGET /api/users/popular_streamer/games\n  ↓\nRedis cache (key: user:123:games, TTL: 60 sec)\n  ↓ Cache miss\nPostgres (indexed by user_id + time)\n```\n\n**For hot users:**\n- Cache their recent games\n- Cache their profile stats\n- Rate limit profile API (100 req/min per user)\n\n---\n\n### 🟢 What Scales Well (No Bottleneck):\n\n1. **User Service** - reads are cacheable, writes are rare (login/signup)\n2. **Game History Storage** - 90GB/month trivial for Postgres\n3. **Active Game State** - 500MB in-memory manageable\n\n---\n\n## Scaling Summary:\n\n| Component | Bottleneck | Solution |\n|-----------|-----------|----------|\n| **Game Service** | 100K WebSocket connections | Horizontal scaling (5-10 servers) |\n| **Database Writes** | 100 writes/sec | Message queue + async workers |\n| **Leaderboard Reads** | 30 reads/sec | Redis + CDN caching |\n| **Matchmaking** | Queue management | Tiered search + cleanup jobs |\n| **Hot Users** | Popular profiles | User-level caching |\n\n---\n\n## Architecture with Scaling:\n\n```\n         ┌─────┐\n         │ CDN │ (cache leaderboard)\n         └──┬──┘\n            │\n    ┌───────┴────────┐\n    │  Load Balancer │\n    └───────┬────────┘\n            │\n    ┌───────┼────────────────────┐\n    ▼       ▼                    ▼\n[Game    [Game      ...    [Game\n Srv 1]   Srv 2]            Srv N]\n    │       │                    │\n    └───────┴────────────────────┘\n            │\n            ▼\n    ┌──────────────┐\n    │ Message Queue│ (Kafka)\n    └──────┬───────┘\n           │\n    ┌──────┴───────┐\n    │ Async Workers│\n    └──────┬───────┘\n           │\n    ┌──────┼──────────────┐\n    ▼      ▼              ▼\n[Postgres] [Redis]    [Redis\n (Write)   (Match)     Leaderboard]\n```\n\n---\n\n**Good system design interview so far!** Any specific bottleneck you want to dive deeper into? 🚀",
      "fontSize": 20,
      "fontFamily": 5,
      "textAlign": "left",
      "verticalAlign": "top",
      "containerId": null,
      "originalText": "## 1. Index Explanation: (elo_rating DESC, user_id)\n\n### How This Index Works:\n\n```sql\nCREATE INDEX idx_leaderboard ON user_ratings(elo_rating DESC, user_id);\n```\n\n**Index structure (simplified):**\n```\nELO (descending) | user_id     | → Row pointer\n-----------------|-------------|---------------\n2700             | user_789    | → Row in table\n2500             | user_123    | → Row in table\n2300             | user_456    | → Row in table\n2100             | user_999    | → Row in table\n...\n```\n\n### Why This Design?\n\n**Common query:**\n```sql\n-- Get top 100 players\nSELECT user_id, elo_rating, username \nFROM user_ratings \nORDER BY elo_rating DESC \nLIMIT 100;\n```\n\n**With this index:**\n1. Already sorted by ELO descending ✓\n2. Just read first 100 entries ✓\n3. No sorting needed ✓\n4. **O(100)** - constant time!\n\n**`user_id` as second column:**\n- Breaks ties (if two users have same ELO)\n- Makes index unique → better performance\n\n---\n\n## 2. Scaling & Bottlenecks\n\n### Current Load Recap:\n- 50K concurrent games\n- 3,300 moves/sec peak\n- 500K DAU\n- 1M games/day\n\n---\n\n### 🔴 Bottleneck #1: Game Service (WebSocket Connections)\n\n**Problem:**\n- Each game = 2 WebSocket connections\n- 50K games = **100K concurrent WebSocket connections**\n- Single server limit: ~10-20K connections\n\n**Solution: Horizontal Scaling**\n```\n                    ┌──────────────┐\nClient ────────────→│ Load Balancer│\n                    │ (sticky by   │\n                    │  game_id)    │\n                    └──────┬───────┘\n                           │\n        ┌──────────────────┼──────────────────┐\n        ▼                  ▼                  ▼\n   ┌─────────┐        ┌─────────┐       ┌─────────┐\n   │ Game    │        │ Game    │       │ Game    │\n   │ Server 1│        │ Server 2│       │ Server 3│\n   │ (20K    │        │ (20K    │       │ (20K    │\n   │  games) │        │  games) │       │  games) │\n   └─────────┘        └─────────┘       └─────────┘\n```\n\n**Key points:**\n- **Sticky sessions** - both players in same game connect to same server\n- 5-10 game servers for 50K concurrent games\n- Stateful servers (each holds active games in memory)\n\n---\n\n### 🔴 Bottleneck #2: Database Writes (Game Completion)\n\n**Problem:**\n- 24 games/sec completion = 24 writes/sec to Postgres\n- Each write updates:\n  - Game history table (insert)\n  - User ratings (2 updates per game)\n  - Stats tables (wins/losses)\n\n**Write amplification:** 24 games/sec × 4 DB operations = **~100 writes/sec**\n\n**Solution: Write-Behind Pattern**\n```\nGame ends ──→ Message Queue (Kafka/RabbitMQ)\n              │\n              ▼\n         ┌──────────────┐\n         │ Async Workers│ ──→ Batch writes to Postgres\n         │ (consumers)  │ ──→ Update Redis leaderboard\n         └──────────────┘\n```\n\n**Benefits:**\n- Game Service doesn't wait for DB\n- Batch multiple writes together\n- Retry on failure\n- Decouple write spikes\n\n---\n\n### 🔴 Bottleneck #3: Leaderboard Reads\n\n**Problem:**\n- Popular feature - users check rankings frequently\n- Potential: 500K DAU × 5 checks/day = **2.5M reads/day** = 30 reads/sec average\n\n**Solution: Redis + CDN**\n```\nClient ──→ CDN (cache top 1000 for 10 sec)\n           │ Cache miss\n           ▼\n         Redis (global leaderboard)\n           │ Cache miss (rare)\n           ▼\n         Postgres (source of truth)\n```\n\n**Caching strategy:**\n- **CDN/Edge cache:** Top 1000 players, TTL 10 seconds\n- **Redis:** Full leaderboard (10M users), always fresh\n- **Postgres:** Rebuild Redis on restart only\n\n---\n\n### 🔴 Bottleneck #4: Matchmaking at Scale\n\n**Problem:**\n- Peak: 50K concurrent games means ~50K new matchmaking requests/hour\n- Redis sorted set handles this, but queue management tricky\n\n**Challenges:**\n- Players wait too long if no close ELO match\n- Need to widen search range over time\n- Handle abandoned searches (player closes app)\n\n**Solution: Tiered Matchmaking**\n```python\n# Pseudocode\ndef find_match(user_id, elo):\n    ranges = [\n        (elo-50, elo+50),    # Try ±50 first (wait 5 sec)\n        (elo-100, elo+100),  # Widen to ±100 (wait 10 sec)\n        (elo-200, elo+200),  # Widen to ±200 (wait 15 sec)\n    ]\n    \n    for min_elo, max_elo in ranges:\n        opponent = redis.ZRANGEBYSCORE(queue, min_elo, max_elo, limit=1)\n        if opponent:\n            return opponent\n        sleep(5)  # Wait before widening\n    \n    return None  # No match found\n```\n\n**Plus:**\n- Background cleanup job removes stale entries (users who disconnected)\n- Separate queues per time control (blitz, rapid, etc.)\n\n---\n\n### 🔴 Bottleneck #5: Hot User Problem\n\n**Problem:**\n- Streamers/popular players: 100+ games/day\n- Their game history queries slow down\n- Their profile page gets hammered\n\n**Solution: User-level Caching**\n```\nGET /api/users/popular_streamer/games\n  ↓\nRedis cache (key: user:123:games, TTL: 60 sec)\n  ↓ Cache miss\nPostgres (indexed by user_id + time)\n```\n\n**For hot users:**\n- Cache their recent games\n- Cache their profile stats\n- Rate limit profile API (100 req/min per user)\n\n---\n\n### 🟢 What Scales Well (No Bottleneck):\n\n1. **User Service** - reads are cacheable, writes are rare (login/signup)\n2. **Game History Storage** - 90GB/month trivial for Postgres\n3. **Active Game State** - 500MB in-memory manageable\n\n---\n\n## Scaling Summary:\n\n| Component | Bottleneck | Solution |\n|-----------|-----------|----------|\n| **Game Service** | 100K WebSocket connections | Horizontal scaling (5-10 servers) |\n| **Database Writes** | 100 writes/sec | Message queue + async workers |\n| **Leaderboard Reads** | 30 reads/sec | Redis + CDN caching |\n| **Matchmaking** | Queue management | Tiered search + cleanup jobs |\n| **Hot Users** | Popular profiles | User-level caching |\n\n---\n\n## Architecture with Scaling:\n\n```\n         ┌─────┐\n         │ CDN │ (cache leaderboard)\n         └──┬──┘\n            │\n    ┌───────┴────────┐\n    │  Load Balancer │\n    └───────┬────────┘\n            │\n    ┌───────┼────────────────────┐\n    ▼       ▼                    ▼\n[Game    [Game      ...    [Game\n Srv 1]   Srv 2]            Srv N]\n    │       │                    │\n    └───────┴────────────────────┘\n            │\n            ▼\n    ┌──────────────┐\n    │ Message Queue│ (Kafka)\n    └──────┬───────┘\n           │\n    ┌──────┴───────┐\n    │ Async Workers│\n    └──────┬───────┘\n           │\n    ┌──────┼──────────────┐\n    ▼      ▼              ▼\n[Postgres] [Redis]    [Redis\n (Write)   (Match)     Leaderboard]\n```\n\n---\n\n**Good system design interview so far!** Any specific bottleneck you want to dive deeper into? 🚀",
      "autoResize": true,
      "lineHeight": 1.25
    }
  ],
  "appState": {
    "gridSize": 20,
    "gridStep": 5,
    "gridModeEnabled": false,
    "viewBackgroundColor": "#ffffff",
    "lockedMultiSelections": {}
  },
  "files": {}
}